{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch-s8-task7.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DallasAutumn/datawhale_salons/blob/master/PyTorch_s8_task7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8rwbeF0EjUk",
        "colab_type": "text"
      },
      "source": [
        "# PyTorch-s8-task7 手写数字识别"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZf81waREfZn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torchvision\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8Ngd_JCEpIN",
        "colab_type": "code",
        "outputId": "cc288ee6-9671-4363-abac-46ce32928f5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Hyper parameters\n",
        "EPOCH = 3\n",
        "BATCH_SIZE = 32 #@param [8, 16, 32, 64]\n",
        "LR = 0.001 #@param {type:\"number\"}\n",
        "MNIST_ROOT = 'MNIST'\n",
        "DOWNLOAD_MNIST = False if MNIST_ROOT in os.listdir() else True\n",
        "TEST_SIZE = 2000\n",
        "\n",
        "device = torch.device('cuda')\n",
        "print(device, torch.cuda.get_device_name())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-jr5GD8hGvx0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = torchvision.datasets.MNIST(\n",
        "        root=f'./{MNIST_ROOT}', \n",
        "        download=DOWNLOAD_MNIST, \n",
        "        train=True, \n",
        "        transform=torchvision.transforms.ToTensor()\n",
        "    ) # 60000 range(0, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZZeUpMdKQUB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
        "\n",
        "test_data = torchvision.datasets.MNIST(root=f'./{MNIST_ROOT}', train=False)\n",
        "\n",
        "with torch.no_grad():\n",
        "    test_x = Variable(torch.unsqueeze(test_data.data, dim=1)).type(torch.cuda.FloatTensor)[:TEST_SIZE] / 255.\n",
        "    test_y = test_data.targets.type(torch.cuda.LongTensor).squeeze()[:TEST_SIZE]\n",
        "    test_y_for_acc = test_data.targets.numpy().squeeze()[:TEST_SIZE]\n",
        "    test_x.to(device)\n",
        "    test_y.to(device)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAkXFmwaMheG",
        "colab_type": "code",
        "outputId": "6395cd0a-b974-42c5-8c21-7a520cf63a78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2), # padding = (kernel_size - stride) / 2\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=2),\n",
        "        )\n",
        "\n",
        "        self.conv2 = nn.Sequential(\n",
        "            nn.Conv2d(16, 32, 5, 1, 2),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2),\n",
        "        )\n",
        "\n",
        "        self.out = nn.Linear(32 * 7 * 7, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x) # (batch, 32, 7, 7)\n",
        "        x = x.view(x.size(0), -1) # flatten (batch, 32*7*7)\n",
        "        output = self.out(x)\n",
        "        return output\n",
        "\n",
        "cnn = CNN()\n",
        "cnn.to(device)\n",
        "print(cnn)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CNN(\n",
            "  (conv1): Sequential(\n",
            "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (conv2): Sequential(\n",
            "    (0): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
            "    (1): ReLU()\n",
            "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  )\n",
            "  (out): Linear(in_features=1568, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oQLAFpV9Q3I4",
        "colab_type": "code",
        "outputId": "1ffaccc5-5f59-43db-fd85-05a329b3b1bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "optimizer = torch.optim.Adam(cnn.parameters(), lr=LR)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "\n",
        "# training and optimizing\n",
        "for epoch in range(EPOCH):\n",
        "    for step, (x, y) in enumerate(train_loader):\n",
        "        b_x = Variable(x).to(device)\n",
        "        b_y = Variable(y).to(device)\n",
        "\n",
        "        output = cnn(b_x)\n",
        "        loss = loss_func(output, b_y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if step % 50 == 0:\n",
        "            test_output = cnn(test_x)\n",
        "            pred_y_for_acc = torch.max(test_output, 1)[1].cpu().data.numpy().squeeze()\n",
        "            accuracy = sum(pred_y_for_acc == test_y_for_acc) / test_y_for_acc.size\n",
        "            print('Epoch ', epoch, '| train loss : %.4f' % loss.item(), '| test accuracy', accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  0 | train loss : 2.3259 | test accuracy 0.1305\n",
            "Epoch  0 | train loss : 0.7036 | test accuracy 0.696\n",
            "Epoch  0 | train loss : 0.5569 | test accuracy 0.8845\n",
            "Epoch  0 | train loss : 0.3729 | test accuracy 0.886\n",
            "Epoch  0 | train loss : 0.1068 | test accuracy 0.9235\n",
            "Epoch  0 | train loss : 0.0891 | test accuracy 0.9365\n",
            "Epoch  0 | train loss : 0.1185 | test accuracy 0.9455\n",
            "Epoch  0 | train loss : 0.1072 | test accuracy 0.946\n",
            "Epoch  0 | train loss : 0.0192 | test accuracy 0.959\n",
            "Epoch  0 | train loss : 0.0288 | test accuracy 0.96\n",
            "Epoch  0 | train loss : 0.1034 | test accuracy 0.9595\n",
            "Epoch  0 | train loss : 0.0920 | test accuracy 0.9565\n",
            "Epoch  0 | train loss : 0.0595 | test accuracy 0.963\n",
            "Epoch  0 | train loss : 0.1826 | test accuracy 0.966\n",
            "Epoch  0 | train loss : 0.0305 | test accuracy 0.969\n",
            "Epoch  0 | train loss : 0.0452 | test accuracy 0.9665\n",
            "Epoch  0 | train loss : 0.1402 | test accuracy 0.972\n",
            "Epoch  0 | train loss : 0.1787 | test accuracy 0.9695\n",
            "Epoch  0 | train loss : 0.0258 | test accuracy 0.9725\n",
            "Epoch  0 | train loss : 0.0147 | test accuracy 0.9695\n",
            "Epoch  0 | train loss : 0.1551 | test accuracy 0.975\n",
            "Epoch  0 | train loss : 0.0194 | test accuracy 0.9715\n",
            "Epoch  0 | train loss : 0.0778 | test accuracy 0.972\n",
            "Epoch  0 | train loss : 0.1701 | test accuracy 0.975\n",
            "Epoch  0 | train loss : 0.0520 | test accuracy 0.9755\n",
            "Epoch  0 | train loss : 0.0572 | test accuracy 0.977\n",
            "Epoch  0 | train loss : 0.0233 | test accuracy 0.9775\n",
            "Epoch  0 | train loss : 0.0496 | test accuracy 0.976\n",
            "Epoch  0 | train loss : 0.0732 | test accuracy 0.9685\n",
            "Epoch  0 | train loss : 0.0678 | test accuracy 0.975\n",
            "Epoch  0 | train loss : 0.0291 | test accuracy 0.98\n",
            "Epoch  0 | train loss : 0.0246 | test accuracy 0.9785\n",
            "Epoch  0 | train loss : 0.0632 | test accuracy 0.976\n",
            "Epoch  0 | train loss : 0.0266 | test accuracy 0.9755\n",
            "Epoch  0 | train loss : 0.0916 | test accuracy 0.9785\n",
            "Epoch  0 | train loss : 0.0020 | test accuracy 0.971\n",
            "Epoch  0 | train loss : 0.0177 | test accuracy 0.977\n",
            "Epoch  0 | train loss : 0.0388 | test accuracy 0.9765\n",
            "Epoch  1 | train loss : 0.0103 | test accuracy 0.977\n",
            "Epoch  1 | train loss : 0.0035 | test accuracy 0.9805\n",
            "Epoch  1 | train loss : 0.0252 | test accuracy 0.9795\n",
            "Epoch  1 | train loss : 0.0702 | test accuracy 0.9745\n",
            "Epoch  1 | train loss : 0.1006 | test accuracy 0.9795\n",
            "Epoch  1 | train loss : 0.0149 | test accuracy 0.9805\n",
            "Epoch  1 | train loss : 0.0944 | test accuracy 0.979\n",
            "Epoch  1 | train loss : 0.1948 | test accuracy 0.982\n",
            "Epoch  1 | train loss : 0.0291 | test accuracy 0.979\n",
            "Epoch  1 | train loss : 0.0117 | test accuracy 0.9805\n",
            "Epoch  1 | train loss : 0.0109 | test accuracy 0.9835\n",
            "Epoch  1 | train loss : 0.0044 | test accuracy 0.982\n",
            "Epoch  1 | train loss : 0.0688 | test accuracy 0.9835\n",
            "Epoch  1 | train loss : 0.0043 | test accuracy 0.9805\n",
            "Epoch  1 | train loss : 0.0037 | test accuracy 0.983\n",
            "Epoch  1 | train loss : 0.0062 | test accuracy 0.983\n",
            "Epoch  1 | train loss : 0.0517 | test accuracy 0.98\n",
            "Epoch  1 | train loss : 0.0226 | test accuracy 0.9835\n",
            "Epoch  1 | train loss : 0.0322 | test accuracy 0.974\n",
            "Epoch  1 | train loss : 0.0044 | test accuracy 0.9845\n",
            "Epoch  1 | train loss : 0.0236 | test accuracy 0.9845\n",
            "Epoch  1 | train loss : 0.0516 | test accuracy 0.9815\n",
            "Epoch  1 | train loss : 0.0666 | test accuracy 0.9805\n",
            "Epoch  1 | train loss : 0.0248 | test accuracy 0.981\n",
            "Epoch  1 | train loss : 0.0542 | test accuracy 0.9825\n",
            "Epoch  1 | train loss : 0.0729 | test accuracy 0.984\n",
            "Epoch  1 | train loss : 0.0386 | test accuracy 0.9845\n",
            "Epoch  1 | train loss : 0.0079 | test accuracy 0.9835\n",
            "Epoch  1 | train loss : 0.0139 | test accuracy 0.9825\n",
            "Epoch  1 | train loss : 0.0052 | test accuracy 0.9825\n",
            "Epoch  1 | train loss : 0.0266 | test accuracy 0.984\n",
            "Epoch  1 | train loss : 0.0056 | test accuracy 0.9765\n",
            "Epoch  1 | train loss : 0.2239 | test accuracy 0.9775\n",
            "Epoch  1 | train loss : 0.0479 | test accuracy 0.9815\n",
            "Epoch  1 | train loss : 0.0145 | test accuracy 0.9835\n",
            "Epoch  1 | train loss : 0.0017 | test accuracy 0.984\n",
            "Epoch  1 | train loss : 0.0387 | test accuracy 0.984\n",
            "Epoch  1 | train loss : 0.0240 | test accuracy 0.982\n",
            "Epoch  2 | train loss : 0.0855 | test accuracy 0.9825\n",
            "Epoch  2 | train loss : 0.4909 | test accuracy 0.9795\n",
            "Epoch  2 | train loss : 0.0097 | test accuracy 0.986\n",
            "Epoch  2 | train loss : 0.0623 | test accuracy 0.984\n",
            "Epoch  2 | train loss : 0.0068 | test accuracy 0.983\n",
            "Epoch  2 | train loss : 0.0009 | test accuracy 0.987\n",
            "Epoch  2 | train loss : 0.0738 | test accuracy 0.9825\n",
            "Epoch  2 | train loss : 0.0276 | test accuracy 0.9845\n",
            "Epoch  2 | train loss : 0.0069 | test accuracy 0.9815\n",
            "Epoch  2 | train loss : 0.0187 | test accuracy 0.9805\n",
            "Epoch  2 | train loss : 0.1558 | test accuracy 0.9825\n",
            "Epoch  2 | train loss : 0.0141 | test accuracy 0.9855\n",
            "Epoch  2 | train loss : 0.0810 | test accuracy 0.983\n",
            "Epoch  2 | train loss : 0.0035 | test accuracy 0.9835\n",
            "Epoch  2 | train loss : 0.0470 | test accuracy 0.9835\n",
            "Epoch  2 | train loss : 0.0666 | test accuracy 0.985\n",
            "Epoch  2 | train loss : 0.0037 | test accuracy 0.983\n",
            "Epoch  2 | train loss : 0.0214 | test accuracy 0.987\n",
            "Epoch  2 | train loss : 0.0160 | test accuracy 0.9825\n",
            "Epoch  2 | train loss : 0.0030 | test accuracy 0.987\n",
            "Epoch  2 | train loss : 0.0745 | test accuracy 0.984\n",
            "Epoch  2 | train loss : 0.0312 | test accuracy 0.983\n",
            "Epoch  2 | train loss : 0.0008 | test accuracy 0.984\n",
            "Epoch  2 | train loss : 0.0018 | test accuracy 0.982\n",
            "Epoch  2 | train loss : 0.0353 | test accuracy 0.988\n",
            "Epoch  2 | train loss : 0.0262 | test accuracy 0.983\n",
            "Epoch  2 | train loss : 0.0015 | test accuracy 0.984\n",
            "Epoch  2 | train loss : 0.0013 | test accuracy 0.988\n",
            "Epoch  2 | train loss : 0.0855 | test accuracy 0.9865\n",
            "Epoch  2 | train loss : 0.0692 | test accuracy 0.986\n",
            "Epoch  2 | train loss : 0.0289 | test accuracy 0.985\n",
            "Epoch  2 | train loss : 0.0064 | test accuracy 0.986\n",
            "Epoch  2 | train loss : 0.0037 | test accuracy 0.9885\n",
            "Epoch  2 | train loss : 0.0010 | test accuracy 0.985\n",
            "Epoch  2 | train loss : 0.0131 | test accuracy 0.9875\n",
            "Epoch  2 | train loss : 0.2157 | test accuracy 0.9785\n",
            "Epoch  2 | train loss : 0.0080 | test accuracy 0.984\n",
            "Epoch  2 | train loss : 0.0020 | test accuracy 0.9845\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}